name: Bootstrap Infrastructure

# Manual trigger only â€” not part of CI.
# Use the "Run workflow" button in the Actions tab to launch.
on:
  workflow_dispatch:
    inputs:
      cluster_name:
        description: "Kubernetes cluster name"
        required: false
        default: "dkpbot-prod"
      hcloud_region:
        description: "Hetzner Cloud region (nbg1, fsn1, hel1)"
        required: false
        default: "nbg1"
      control_plane_count:
        description: "Number of control-plane nodes (keep low for Hetzner limits)"
        required: false
        default: "1"
      worker_count:
        description: "Number of worker nodes (keep low for Hetzner limits)"
        required: false
        default: "1"
      machine_type:
        description: "Hetzner machine type (cx23, cx33, cx43, etc.)"
        required: false
        default: "cx23"
      kubernetes_version:
        description: "Kubernetes version"
        required: false
        default: "v1.31.6"
      discord_token:
        description: "Discord bot token (leave empty to use repo secret DISCORD_TOKEN)"
        required: false
        default: ""
      discord_guild_id:
        description: "Discord guild ID (leave empty to use repo secret DISCORD_GUILD_ID)"
        required: false
        default: ""
      cnpg_s3_endpoint:
        description: "Hetzner S3 endpoint URL (e.g. https://nbg1.your-objectstorage.com)"
        required: false
        default: ""
      cnpg_s3_bucket:
        description: "S3 bucket name for CNPG backups"
        required: false
        default: "dkpbot-backups"
      flux_branch:
        description: "Git branch for FluxCD to track (defaults to the branch you dispatch from)"
        required: false
        default: ""

# Required GitHub repository secrets (Settings â†’ Secrets and variables â†’ Actions):
#
#   HCLOUD_TOKEN         â€” Hetzner Cloud API token
#   CNPG_S3_ACCESS_KEY   â€” Hetzner Object Storage access key ID
#   CNPG_S3_SECRET_KEY   â€” Hetzner Object Storage secret access key
#
# Optional secrets:
#   HCLOUD_SSH_KEY       â€” SSH key name in Hetzner console (defaults to "dkpbot-ssh")
#   HCLOUD_SSH_PUBKEY    â€” SSH public key content to upload (auto-generated if not set)
#   DISCORD_TOKEN        â€” Discord bot token (can also be passed as workflow input)
#   DISCORD_GUILD_ID     â€” Discord guild ID (can also be passed as workflow input)

permissions:
  contents: write    # Flux bootstrap commits to the repo

jobs:
  bootstrap:
    name: Bootstrap Hetzner Cluster
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      CLUSTER_NAME: ${{ inputs.cluster_name }}
      HCLOUD_TOKEN: ${{ secrets.HCLOUD_TOKEN }}
      HCLOUD_SSH_KEY: ${{ secrets.HCLOUD_SSH_KEY || 'dkpbot-ssh' }}
      HCLOUD_REGION: ${{ inputs.hcloud_region }}
      CONTROL_PLANE_MACHINE_COUNT: ${{ inputs.control_plane_count }}
      WORKER_MACHINE_COUNT: ${{ inputs.worker_count }}
      HCLOUD_CONTROL_PLANE_MACHINE_TYPE: ${{ inputs.machine_type }}
      HCLOUD_WORKER_MACHINE_TYPE: ${{ inputs.machine_type }}
      HCLOUD_NETWORK_ZONE: "eu-central"
      KUBERNETES_VERSION: ${{ inputs.kubernetes_version }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      GITHUB_USER: ${{ github.repository_owner }}

    steps:
      - name: Validate secrets
        run: |
          if [[ -z "${HCLOUD_TOKEN}" ]]; then
            echo "::error::HCLOUD_TOKEN secret is not set. Configure it in Settings â†’ Secrets."
            exit 1
          fi

          # Verify the token is valid by making a lightweight API call
          CURL_OUT=$(mktemp)
          HTTP_CODE=$(curl -s -o "${CURL_OUT}" -w "%{http_code}" \
            -H "Authorization: Bearer ${HCLOUD_TOKEN}" \
            "https://api.hetzner.cloud/v1/locations?per_page=1") || {
            echo "::warning::Could not reach Hetzner API (network error). Continuing anyway."
            HTTP_CODE="000"
          }
          rm -f "${CURL_OUT}"
          if [[ "${HTTP_CODE}" == "401" || "${HTTP_CODE}" == "403" ]]; then
            echo "::error::HCLOUD_TOKEN is set but invalid (HTTP ${HTTP_CODE}). Verify your Hetzner Cloud API token in Settings â†’ Secrets."
            exit 1
          fi
          if [[ "${HTTP_CODE}" == "200" ]]; then
            echo "âœ… HCLOUD_TOKEN is valid."
          elif [[ "${HTTP_CODE}" != "000" ]]; then
            echo "::warning::Unexpected response from Hetzner API (HTTP ${HTTP_CODE}). Continuing anyway."
          fi

          if [[ -z "${{ secrets.CNPG_S3_ACCESS_KEY }}" ]]; then
            echo "::warning::CNPG_S3_ACCESS_KEY secret is not set. CNPG backups will not work until you create the backup-s3-credentials Secret manually."
          fi
          if [[ -z "${{ secrets.CNPG_S3_SECRET_KEY }}" ]]; then
            echo "::warning::CNPG_S3_SECRET_KEY secret is not set. CNPG backups will not work until you create the backup-s3-credentials Secret manually."
          fi

      - uses: actions/checkout@v4

      # â”€â”€ Install tooling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Install Kind
        run: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.25.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind

      - name: Install clusterctl
        run: |
          curl -Lo ./clusterctl https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.9.4/clusterctl-linux-amd64
          chmod +x ./clusterctl
          sudo mv ./clusterctl /usr/local/bin/clusterctl

      - name: Install Flux CLI
        run: |
          curl -s https://fluxcd.io/install.sh | sudo bash

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: "v3.16.4"

      - name: Install kubectl
        uses: azure/setup-kubectl@v4

      # â”€â”€ Step 1: Kind management cluster â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 1: Create Kind management cluster"
        run: |
          kind create cluster --name capi-management
          kubectl config use-context kind-capi-management

      # â”€â”€ Step 2: Install CAPI + Hetzner provider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 2: Install Cluster API with Hetzner provider"
        run: |
          export EXP_CLUSTER_RESOURCE_SET="true"
          clusterctl init --core cluster-api --bootstrap kubeadm --control-plane kubeadm --infrastructure hetzner

          echo "Waiting for CAPI core controller..."
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/capi-controller-manager -n capi-system

          echo "Waiting for KubeadmControlPlane controller..."
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/capi-kubeadm-control-plane-controller-manager -n capi-kubeadm-control-plane-system

          echo "Waiting for KubeadmBootstrap controller..."
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/capi-kubeadm-bootstrap-controller-manager -n capi-kubeadm-bootstrap-system

          echo "Waiting for CAPH controllers..."
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/caph-controller-manager -n caph-system

          echo "Waiting for Hetzner CRDs to be established..."
          kubectl wait --for=condition=Established --timeout=60s \
            crd/hetznerclusters.infrastructure.cluster.x-k8s.io \
            crd/hcloudmachinetemplates.infrastructure.cluster.x-k8s.io

          echo "Waiting for CAPH webhook service to be ready..."
          until kubectl -n caph-system get endpoints caph-webhook-service \
              -o jsonpath='{.subsets[*].addresses[*].ip}' 2>/dev/null | grep -q '.'; do
            sleep 2
          done
          echo "âœ… CAPH webhook service is ready."

      # â”€â”€ Step 3: Create Hetzner secret â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 3: Create Hetzner secret"
        run: |
          kubectl create secret generic hetzner \
            --from-literal=hcloud="${HCLOUD_TOKEN}" \
            --dry-run=client -o yaml | kubectl apply -f -

          # Label the secret so clusterctl move copies it to the workload cluster
          kubectl patch secret hetzner -p '{"metadata":{"labels":{"clusterctl.cluster.x-k8s.io/move":""}}}'

      # â”€â”€ Step 3a: Pre-flight Hetzner limit check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 3a: Pre-flight Hetzner limit check"
        run: |
          NEEDED=$(( CONTROL_PLANE_MACHINE_COUNT + WORKER_MACHINE_COUNT ))
          echo "Requesting ${NEEDED} server(s): ${CONTROL_PLANE_MACHINE_COUNT} control-plane + ${WORKER_MACHINE_COUNT} worker(s)"

          # Query existing servers in this project
          RESP=$(curl -sf -H "Authorization: Bearer ${HCLOUD_TOKEN}" \
            "https://api.hetzner.cloud/v1/servers?per_page=50" 2>&1) || {
            echo "::warning::Could not query Hetzner API. Continuing anyway."
            exit 0
          }

          CURRENT=$(echo "${RESP}" | jq '.servers | length')
          echo "Currently running servers: ${CURRENT}"

          if [[ "${CURRENT}" -gt 0 ]]; then
            echo "::warning::You have ${CURRENT} existing server(s) on this Hetzner project."
            echo "::warning::If provisioning fails, you may have hit Hetzner server/vCPU limits."
            echo "::warning::Delete unused servers or request a limit increase at https://console.hetzner.cloud"
            echo "Existing servers:"
            echo "${RESP}" | jq -r '.servers[] | "  - \(.name) (\(.server_type.name), \(.status))"'
          fi

          echo "Will attempt to create ${NEEDED} additional server(s)."

      # â”€â”€ Step 3b: Ensure SSH key exists in Hetzner Cloud â”€â”€â”€â”€â”€
      - name: "Step 3b: Ensure SSH key exists in Hetzner Cloud"
        run: |
          SSH_KEY_NAME="${HCLOUD_SSH_KEY}"
          echo "Checking if SSH key '${SSH_KEY_NAME}' exists in Hetzner Cloud..."

          ENCODED_NAME=$(jq -rn --arg n "${SSH_KEY_NAME}" '$n|@uri')
          RESP=$(curl -sf -H "Authorization: Bearer ${HCLOUD_TOKEN}" \
            "https://api.hetzner.cloud/v1/ssh_keys?name=${ENCODED_NAME}" 2>&1) || {
            echo "::error::Could not query Hetzner Cloud SSH keys API."
            exit 1
          }

          KEY_COUNT=$(echo "${RESP}" | jq '.ssh_keys | length')

          if [[ "${KEY_COUNT}" -gt 0 ]]; then
            echo "âœ… SSH key '${SSH_KEY_NAME}' already exists in Hetzner Cloud."
          else
            echo "SSH key '${SSH_KEY_NAME}' not found in Hetzner Cloud. Creating..."

            # Use the provided public key or generate a new key pair
            SSH_PUBKEY="${{ secrets.HCLOUD_SSH_PUBKEY }}"
            if [[ -n "${SSH_PUBKEY}" ]]; then
              echo "Using SSH public key from HCLOUD_SSH_PUBKEY secret."
            else
              echo "No HCLOUD_SSH_PUBKEY secret set â€” generating a new Ed25519 key pair."
              TMPDIR=$(mktemp -d)
              ssh-keygen -t ed25519 -f "${TMPDIR}/hcloud-ssh-key" -N "" -C "dkpbot-bootstrap" >/dev/null 2>&1
              SSH_PUBKEY=$(cat "${TMPDIR}/hcloud-ssh-key.pub")
              rm -rf "${TMPDIR}"
            fi

            HTTP_CODE=$(curl -s -o /tmp/ssh-create-resp.json -w "%{http_code}" \
              -X POST \
              -H "Authorization: Bearer ${HCLOUD_TOKEN}" \
              -H "Content-Type: application/json" \
              --data "$(jq -n --arg name "${SSH_KEY_NAME}" --arg key "${SSH_PUBKEY}" \
                '{name: $name, public_key: $key}')" \
              "https://api.hetzner.cloud/v1/ssh_keys")

            if [[ "${HTTP_CODE}" =~ ^2 ]]; then
              echo "âœ… SSH key '${SSH_KEY_NAME}' created in Hetzner Cloud."
            else
              echo "::error::Failed to create SSH key (HTTP ${HTTP_CODE})."
              cat /tmp/ssh-create-resp.json
              rm -f /tmp/ssh-create-resp.json
              exit 1
            fi
            rm -f /tmp/ssh-create-resp.json
          fi

      # â”€â”€ Step 4: Apply cluster manifests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 4: Apply cluster manifests"
        run: |
          # Template replica counts, machine types, and SSH key name from workflow inputs into manifests
          sed -e "s/replicas: 3/replicas: ${CONTROL_PLANE_MACHINE_COUNT}/" \
              -e "s/type: cx23/type: ${HCLOUD_CONTROL_PLANE_MACHINE_TYPE}/" \
            deploy/infrastructure/control-plane.yaml > /tmp/control-plane.yaml

          sed -e "s/replicas: 2/replicas: ${WORKER_MACHINE_COUNT}/" \
              -e "s/type: cx23/type: ${HCLOUD_WORKER_MACHINE_TYPE}/" \
            deploy/infrastructure/workers.yaml > /tmp/workers.yaml

          sed "s/name: dkpbot-ssh/name: ${HCLOUD_SSH_KEY}/" \
            deploy/infrastructure/cluster.yaml > /tmp/cluster.yaml

          kubectl apply -f /tmp/cluster.yaml
          kubectl apply -f /tmp/control-plane.yaml
          kubectl apply -f /tmp/workers.yaml

          # Verify CAPH controller is still healthy after applying manifests
          echo "Waiting 15s for controller to reconcile..."
          sleep 15
          POD_COUNT=$(kubectl get pod -n caph-system -l control-plane=caph-controller-manager \
            -o jsonpath='{.items}' 2>/dev/null | python3 -c "import sys,json; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
          if [[ "${POD_COUNT}" == "0" ]]; then
            echo "::warning::CAPH controller pod not found. The controller may have crashed."
            kubectl get pods -n caph-system 2>&1 || true
          else
            RESTARTS=$(kubectl get pod -n caph-system -l control-plane=caph-controller-manager \
              -o jsonpath='{.items[0].status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
            if [[ "${RESTARTS}" -gt 0 ]]; then
              echo "::warning::CAPH controller has restarted ${RESTARTS} time(s). Checking logs for panics..."
              kubectl logs deployment/caph-controller-manager -n caph-system --tail=30 2>&1 || true
            else
              echo "âœ… CAPH controller is healthy (0 restarts)."
            fi
          fi

      # â”€â”€ Step 4a: Start background provisioning logger â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 4a: Start provisioning debug logger"
        run: |
          LOG="/tmp/bootstrap-debug.log"
          echo "=== Bootstrap provisioning log ===" > "${LOG}"
          echo "Cluster: ${CLUSTER_NAME}" >> "${LOG}"
          echo "Started: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "${LOG}"
          echo "" >> "${LOG}"

          # Background loop: capture CRD states and events every 30s
          (
            while true; do
              {
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo "  Snapshot at $(date -u +%Y-%m-%dT%H:%M:%SZ)"
                echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
                echo ""
                echo "â–¸ Clusters:"
                kubectl get clusters -A -o wide 2>/dev/null || echo "  (not available)"
                echo ""
                echo "â–¸ HetznerClusters:"
                kubectl get hetznerclusters -A -o wide 2>/dev/null || echo "  (not available)"
                echo ""
                echo "â–¸ KubeadmControlPlanes:"
                kubectl get kubeadmcontrolplane -A -o wide 2>/dev/null || echo "  (not available)"
                echo ""
                echo "â–¸ Machines:"
                kubectl get machines -A -o wide 2>/dev/null || echo "  (not available)"
                echo ""
                echo "â–¸ MachineDeployments:"
                kubectl get machinedeployment -A -o wide 2>/dev/null || echo "  (not available)"
                echo ""
                echo "â–¸ HCloudMachines:"
                kubectl get hcloudmachines -A -o wide 2>/dev/null || echo "  (not available)"
                echo ""
                echo "â–¸ Recent events (last 20):"
                kubectl get events --sort-by='.lastTimestamp' -A 2>/dev/null | tail -20 || echo "  (not available)"
                echo ""
              } >> "${LOG}" 2>&1
              sleep 30
            done
          ) &
          echo $! > /tmp/debug-logger.pid
          echo "Background debug logger started (PID $(cat /tmp/debug-logger.pid)), writing to ${LOG}"

      # â”€â”€ Step 5: Wait for control plane to initialize â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # We wait for KubeadmControlPlane.status.initialized=true (kubeadm init
      # has run and the API server is reachable) rather than cluster.Ready=true.
      # The cluster cannot be Ready until nodes are Ready, and nodes cannot be
      # Ready until CNI is installed â€” which happens in Step 8. We install CNI
      # first, then let the cluster reach Ready on its own before the pivot.
      - name: "Step 5: Wait for control plane to initialize"
        run: |
          echo "Waiting for control plane to initialize (kubeadm init, up to 20 minutes)..."
          SECONDS=0
          TIMEOUT=1200
          INTERVAL=30
          while (( SECONDS < TIMEOUT )); do
            INITIALIZED=$(kubectl get kubeadmcontrolplane \
              -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" \
              -o jsonpath='{.items[0].status.initialized}' 2>/dev/null || true)
            if [[ "${INITIALIZED}" == "true" ]]; then
              echo "âœ… Control plane initialized after ${SECONDS}s"
              exit 0
            fi

            echo "â”€â”€â”€â”€ Status at ${SECONDS}s â”€â”€â”€â”€"
            echo "â–¸ Cluster:"
            kubectl get cluster "${CLUSTER_NAME}" -o wide 2>/dev/null || true
            echo "â–¸ HetznerCluster:"
            kubectl get hetznercluster "${CLUSTER_NAME}" -o wide 2>/dev/null || true
            echo "â–¸ KubeadmControlPlane:"
            kubectl get kubeadmcontrolplane -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" -o wide 2>/dev/null || true
            echo "â–¸ Machines:"
            kubectl get machines -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" -o wide 2>/dev/null || true
            echo "â–¸ MachineDeployments:"
            kubectl get machinedeployment -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" -o wide 2>/dev/null || true
            echo ""

            if (( SECONDS + INTERVAL >= TIMEOUT )); then
              break
            fi
            sleep "${INTERVAL}"
          done

          echo "::error::Timed out after ${SECONDS}s waiting for control plane to initialize (timeout: ${TIMEOUT}s)"
          exit 1

      # â”€â”€ Step 5a: Debug diagnostics on failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 5a: Cluster provisioning diagnostics"
        if: failure()
        run: |
          LOG="/tmp/bootstrap-debug.log"
          echo "## ðŸ” Cluster Provisioning Diagnostics" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          {
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "  FAILURE DIAGNOSTICS at $(date -u +%Y-%m-%dT%H:%M:%SZ)"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""

            echo "=== Cluster describe ==="
            kubectl describe cluster "${CLUSTER_NAME}" 2>&1 || true
            echo ""

            echo "=== HetznerCluster describe ==="
            kubectl describe hetznercluster "${CLUSTER_NAME}" 2>&1 || true
            echo ""

            echo "=== KubeadmControlPlane describe ==="
            kubectl describe kubeadmcontrolplane -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" 2>&1 || true
            echo ""

            echo "=== Machines describe ==="
            kubectl describe machines -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" 2>&1 || true
            echo ""

            echo "=== MachineDeployments describe ==="
            kubectl describe machinedeployment -l "cluster.x-k8s.io/cluster-name=${CLUSTER_NAME}" 2>&1 || true
            echo ""

            echo "=== Cluster API events (last 50) ==="
            kubectl get events --sort-by='.lastTimestamp' 2>&1 | tail -50 || true
            echo ""

            echo "=== CAPH controller logs (last 80 lines) ==="
            kubectl logs deployment/caph-controller-manager -n caph-system --tail=80 2>&1 || true
          } | tee -a "${LOG}"

      # â”€â”€ Step 6: Get workload kubeconfig â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 6: Get workload cluster kubeconfig"
        run: |
          clusterctl get kubeconfig "${CLUSTER_NAME}" > /tmp/workload.kubeconfig
          echo "KUBECONFIG=/tmp/workload.kubeconfig" >> "$GITHUB_ENV"

      # â”€â”€ Step 7: Install Hetzner CCM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 7: Install Hetzner Cloud Controller Manager"
        run: |
          kubectl create secret generic hetzner \
            --from-literal=token="${HCLOUD_TOKEN}" \
            --from-literal=network="${CLUSTER_NAME}" \
            -n kube-system --dry-run=client -o yaml | kubectl apply -f -

          helm repo add hcloud https://charts.hetzner.cloud
          helm repo update
          helm install hccm hcloud/hcloud-cloud-controller-manager \
            -n kube-system \
            --set env.HCLOUD_TOKEN.valueFrom.secretKeyRef.name=hetzner \
            --set env.HCLOUD_TOKEN.valueFrom.secretKeyRef.key=token

      # â”€â”€ Step 8: Install Cilium CNI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 8: Install Cilium CNI"
        run: |
          helm repo add cilium https://helm.cilium.io/
          helm install cilium cilium/cilium \
            -n kube-system \
            --set ipam.mode=kubernetes

          echo "Waiting for nodes to become Ready..."
          kubectl wait --for=condition=Ready nodes --all --timeout=300s

      # â”€â”€ Step 9: Pivot CAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 9: Pivot CAPI management to workload cluster"
        run: |
          # Switch back to management cluster (KUBECONFIG was pointing at workload)
          export KUBECONFIG=""

          # Wait for cluster.Ready=True before pivoting. All control plane nodes
          # must be Ready (Cilium DaemonSet propagates as they join). For multi-node
          # clusters this can take several minutes beyond Step 8's node wait.
          echo "Waiting for cluster to be fully Ready (up to 15 min)..."
          kubectl wait --for=condition=Ready \
            "cluster/${CLUSTER_NAME}" --timeout=900s

          clusterctl move \
            --to-kubeconfig=/tmp/workload.kubeconfig

          # Switch to workload cluster for remaining steps
          echo "KUBECONFIG=/tmp/workload.kubeconfig" >> "$GITHUB_ENV"

      # â”€â”€ Step 10: Bootstrap FluxCD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 10: Bootstrap FluxCD"
        run: |
          # Use the input if provided, otherwise use the branch this workflow was dispatched from
          FLUX_BRANCH="${{ inputs.flux_branch }}"
          FLUX_BRANCH="${FLUX_BRANCH:-${{ github.ref_name }}}"

          echo "FluxCD will track branch: ${FLUX_BRANCH}"

          flux bootstrap github \
            --owner="${GITHUB_USER}" \
            --repository="${{ github.event.repository.name }}" \
            --branch="${FLUX_BRANCH}" \
            --path=deploy/flux \
            --personal \
            --token-auth

      # â”€â”€ Step 11: Apply Flux resources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 11: Apply Flux Kustomizations and ConfigMaps"
        run: |
          kubectl apply -f deploy/flux/kustomizations/helm-values-configmaps.yaml
          kubectl apply -f deploy/flux/kustomizations/

      # â”€â”€ Step 12: Create CNPG backup S3 credentials â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # The backup-s3-credentials Secret must exist in the dkpbot
      # namespace BEFORE the CNPG Cluster resource is reconciled.
      # It is referenced by deploy/cloudnative-pg/cluster.yaml.
      - name: "Step 12: Create CNPG S3 backup credentials"
        run: |
          S3_ACCESS="${{ secrets.CNPG_S3_ACCESS_KEY }}"
          S3_SECRET="${{ secrets.CNPG_S3_SECRET_KEY }}"

          # Ensure the namespace exists (Flux may not have created it yet)
          kubectl create namespace dkpbot --dry-run=client -o yaml | kubectl apply -f -

          if [[ -n "${S3_ACCESS}" && -n "${S3_SECRET}" ]]; then
            kubectl -n dkpbot create secret generic backup-s3-credentials \
              --from-literal=ACCESS_KEY_ID="${S3_ACCESS}" \
              --from-literal=ACCESS_SECRET_KEY="${S3_SECRET}" \
              --dry-run=client -o yaml | kubectl apply -f -
            echo "âœ… backup-s3-credentials Secret created in dkpbot namespace."
          else
            echo "::warning::CNPG_S3_ACCESS_KEY and/or CNPG_S3_SECRET_KEY secrets are not set."
            echo "::warning::CNPG backups will NOT work. Create the Secret manually after bootstrap:"
            echo "::warning::  kubectl -n dkpbot create secret generic backup-s3-credentials \\"
            echo "::warning::    --from-literal=ACCESS_KEY_ID=<your-key> \\"
            echo "::warning::    --from-literal=ACCESS_SECRET_KEY=<your-secret>"
          fi

      # â”€â”€ Step 13: Create DKP bot secrets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 13: Create DKP bot secrets"
        run: |
          DISCORD_TOK="${{ inputs.discord_token }}"
          DISCORD_GID="${{ inputs.discord_guild_id }}"

          # Fall back to repo secrets if inputs are empty
          if [[ -z "${DISCORD_TOK}" ]]; then
            DISCORD_TOK="${{ secrets.DISCORD_TOKEN }}"
          fi
          if [[ -z "${DISCORD_GID}" ]]; then
            DISCORD_GID="${{ secrets.DISCORD_GUILD_ID }}"
          fi

          # Use placeholder if still empty
          DISCORD_TOK="${DISCORD_TOK:-REPLACE_ME}"
          DISCORD_GID="${DISCORD_GID:-REPLACE_ME}"

          if [[ "${DISCORD_TOK}" == "REPLACE_ME" || "${DISCORD_GID}" == "REPLACE_ME" ]]; then
            echo "::warning::Discord credentials not provided. The bot will not start until you update the dkpbot-secrets Secret with real values."
          fi

          kubectl -n flux-system create secret generic dkpbot-secrets \
            --from-literal=config.discord.token="${DISCORD_TOK}" \
            --from-literal=config.discord.guild_id="${DISCORD_GID}" \
            --dry-run=client -o yaml | kubectl apply -f -

      # â”€â”€ Stop debug logger and upload log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Stop provisioning debug logger"
        if: always()
        run: |
          if [[ -f /tmp/debug-logger.pid ]]; then
            PID=$(cat /tmp/debug-logger.pid)
            kill "${PID}" 2>/dev/null || true
            wait "${PID}" 2>/dev/null || true
            echo "Debug logger (PID ${PID}) stopped."
          fi
          LOG="/tmp/bootstrap-debug.log"
          if [[ -f "${LOG}" ]]; then
            echo "" >> "${LOG}"
            echo "=== Log ended at $(date -u +%Y-%m-%dT%H:%M:%SZ) ===" >> "${LOG}"
            echo "Debug log size: $(wc -l < "${LOG}") lines"
          fi

      - name: "Upload provisioning debug log"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bootstrap-debug-log-${{ inputs.cluster_name }}
          path: /tmp/bootstrap-debug.log
          retention-days: 7
          if-no-files-found: warn

      # â”€â”€ Step 14: Clean up Kind â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 14: Delete Kind management cluster"
        if: always()
        run: |
          kind delete cluster --name capi-management || true

      # â”€â”€ Step 15: Upload kubeconfig as artifact â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Step 15: Upload kubeconfig"
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: kubeconfig-${{ inputs.cluster_name }}
          path: /tmp/workload.kubeconfig
          retention-days: 1

      # â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Summary
        if: success()
        run: |
          FLUX_BRANCH="${{ inputs.flux_branch }}"
          FLUX_BRANCH="${FLUX_BRANCH:-${{ github.ref_name }}}"

          echo "## âœ… Cluster \`${CLUSTER_NAME}\` bootstrapped!" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "**Region:** ${HCLOUD_REGION}" >> "$GITHUB_STEP_SUMMARY"
          echo "**Kubernetes:** ${KUBERNETES_VERSION}" >> "$GITHUB_STEP_SUMMARY"
          echo "**FluxCD branch:** \`${FLUX_BRANCH}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "**Control Plane:** ${CONTROL_PLANE_MACHINE_COUNT}Ã— ${HCLOUD_CONTROL_PLANE_MACHINE_TYPE}" >> "$GITHUB_STEP_SUMMARY"
          echo "**Workers:** ${WORKER_MACHINE_COUNT}Ã— ${HCLOUD_WORKER_MACHINE_TYPE}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "### FluxCD is now managing:" >> "$GITHUB_STEP_SUMMARY"
          echo "- CloudNative-PG operator + PostgreSQL 16.6 cluster" >> "$GITHUB_STEP_SUMMARY"
          echo "- Observability stack (Prometheus, Grafana, Loki, Tempo)" >> "$GITHUB_STEP_SUMMARY"
          echo "- DKP bot (HelmRelease)" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "### Secrets status" >> "$GITHUB_STEP_SUMMARY"
          if [[ -n "${{ secrets.CNPG_S3_ACCESS_KEY }}" && -n "${{ secrets.CNPG_S3_SECRET_KEY }}" ]]; then
            echo "- âœ… \`backup-s3-credentials\` â€” CNPG S3 backups configured" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "- âš ï¸ \`backup-s3-credentials\` â€” **not configured**. Add \`CNPG_S3_ACCESS_KEY\` and \`CNPG_S3_SECRET_KEY\` repo secrets and re-run, or create manually:" >> "$GITHUB_STEP_SUMMARY"
            echo '  ```' >> "$GITHUB_STEP_SUMMARY"
            echo '  kubectl -n dkpbot create secret generic backup-s3-credentials \' >> "$GITHUB_STEP_SUMMARY"
            echo '    --from-literal=ACCESS_KEY_ID=<key> \' >> "$GITHUB_STEP_SUMMARY"
            echo '    --from-literal=ACCESS_SECRET_KEY=<secret>' >> "$GITHUB_STEP_SUMMARY"
            echo '  ```' >> "$GITHUB_STEP_SUMMARY"
          fi
          if [[ -n "${{ secrets.DISCORD_TOKEN }}" || -n "${{ inputs.discord_token }}" ]]; then
            echo "- âœ… \`dkpbot-secrets\` â€” Discord credentials configured" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "- âš ï¸ \`dkpbot-secrets\` â€” **not configured**. Add \`DISCORD_TOKEN\` and \`DISCORD_GUILD_ID\` repo secrets and re-run" >> "$GITHUB_STEP_SUMMARY"
          fi
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "### Next steps" >> "$GITHUB_STEP_SUMMARY"
          echo "1. Download the kubeconfig artifact from this run" >> "$GITHUB_STEP_SUMMARY"
          echo "2. Check the secrets status above â€” fix any âš ï¸ items" >> "$GITHUB_STEP_SUMMARY"
          if [[ "${FLUX_BRANCH}" != "main" ]]; then
            echo "3. âš ï¸ Flux is tracking branch \`${FLUX_BRANCH}\`, not \`main\`. After testing, re-run the workflow from \`main\` or update the Flux GitRepository to point to \`main\`." >> "$GITHUB_STEP_SUMMARY"
          fi
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "âš ï¸ The kubeconfig artifact expires in 1 day â€” save it securely." >> "$GITHUB_STEP_SUMMARY"
